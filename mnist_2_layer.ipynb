{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_2_layer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/malinenimaurya/Deep-Learning/blob/master/mnist_2_layer.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "TC5XNEBRF3ec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YrHNSJyOHJ12",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model (added multiple hidden layers ) \n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "W1 = tf.Variable(tf.truncated_normal([784, 200], stddev=0.1)) #random initialisations of weights\n",
        "b1 = tf.Variable(tf.ones([200])/10)                           #small positive initialisation for bias\n",
        "W2 = tf.Variable(tf.truncated_normal([200,100], stddev=0.1))\n",
        "b2 = tf.Variable(tf.ones([100])/10)\n",
        "W3 = tf.Variable(tf.truncated_normal([100,50], stddev=0.1))\n",
        "b3 = tf.Variable(tf.ones([50])/10)\n",
        "W4 = tf.Variable(tf.truncated_normal([50,10], stddev=0.1))\n",
        "b4 = tf.Variable(tf.zeros([10]))\n",
        "Y1 = tf.nn.relu(tf.matmul(X,W1)+b1)                           #can use sigmoid,tanh or relu\n",
        "Y2 = tf.nn.relu(tf.matmul(Y1, W2) + b2)\n",
        "Y3 = tf.nn.relu(tf.matmul(Y2, W3) + b3)\n",
        "Ylogits = tf.matmul(Y3,W4) + b4\n",
        "Y = tf.nn.softmax(Ylogits)\n",
        "# placeholder for correct labels\n",
        "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "# loss function\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_) # handled nan(log0) for cross entropy, different optimisers\n",
        "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
        "\n",
        "# % of correct answers found in batch\n",
        "is_correct = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1NEUXOHRHnT7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(0.003)         #can use RMSprop, Adadelta, gradientdescent etc\n",
        "train_step = optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oVKoAYSwHplk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for i in range(1000):\n",
        "    # load batch of images and correct answers\n",
        "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
        "    train_data={X: batch_X, Y_: batch_Y}\n",
        "\n",
        "    # train\n",
        "    sess.run(train_step, feed_dict=train_data)\n",
        "    if i%50 == 0:\n",
        "      a,c = sess.run([accuracy, cross_entropy], feed_dict=train_data)\n",
        "      print(\"iteration:\"+ str(i) + \", accuracy:\" + str(a) +\", cross_entropy:\"+ str(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CtRfbEofIjn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a,c = sess.run([accuracy, cross_entropy], feed_dict=train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R3XywgUXKFS9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(a,c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ATiDsbGBKLbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data={X: mnist.test.images, Y_: mnist.test.labels}\n",
        "a,c = sess.run([accuracy, cross_entropy], feed_dict=test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TqUSLEaJMepV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(a,c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xBSaMG-gKMxA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}