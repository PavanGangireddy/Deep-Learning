{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_cifar_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/malinenimaurya/Deep-Learning/blob/master/transfer_learning_cifar_aug_keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DV6D2v1WiA8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "11066b76-77f2-488c-95cb-5db72df9adef"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "np.random.seed(10)\n",
        "\n",
        "#Loading data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v2DEEtG5sesB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cf5ebed-d202-4b32-b873-0f2b8d9e61bd"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape[0]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "ssg75TZRfEx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "88bbe485-0648-462c-f257-6e4735f8da87"
      },
      "cell_type": "code",
      "source": [
        "#Normalising the data and dividing the dataset into two halves for training one model from scratch and on other halve to perform transfer learning\n",
        "\n",
        "X1_train = []\n",
        "X1_test = []\n",
        "X2_train = []\n",
        "X2_test = []\n",
        "Y1_train = []\n",
        "Y1_test = []\n",
        "Y2_train = []\n",
        "Y2_test = []\n",
        "\n",
        "for i in range(x_train.shape[0]):\n",
        "    if y_train[i] < 5:\n",
        "        # put data in set 1\n",
        "        X1_train.append(x_train[i]/255.0)\n",
        "        Y1_train.append(y_train[i])\n",
        "    else:\n",
        "        # put data in set 2\n",
        "        X2_train.append(x_train[i]/255.0)\n",
        "        Y2_train.append(y_train[i])\n",
        "\n",
        "for i in range(x_test.shape[0]):\n",
        "    if y_test[i] < 5:\n",
        "        # put data in set 1\n",
        "        X1_test.append(x_test[i]/255.0)\n",
        "        Y1_test.append(y_test[i])\n",
        "    else:\n",
        "        # put data in set 2\n",
        "        X2_test.append(x_test[i]/255.0)\n",
        "        Y2_test.append(y_test[i])\n",
        "\n",
        "#Converting to numpy array\n",
        "\n",
        "X1_train = np.asarray(X1_train).reshape((-1, 32, 32, 3))\n",
        "X1_test = np.asarray(X1_test).reshape((-1, 32, 32, 3))\n",
        "X2_train = np.asarray(X2_train).reshape((-1, 32, 32, 3))\n",
        "X2_test = np.asarray(X2_test).reshape((-1, 32, 32, 3))\n",
        "\n",
        "#one hot encoding\n",
        "Y1_train = to_categorical(Y1_train)\n",
        "Y1_test = to_categorical(Y1_test)\n",
        "\n",
        "Y2_train = to_categorical(Y2_train)\n",
        "Y2_test = to_categorical(Y2_test)\n",
        "\n",
        "print (X1_train.shape, X1_test.shape)\n",
        "print (Y1_train.shape, Y1_test.shape)\n",
        "print (X2_train.shape, X2_test.shape)\n",
        "print (Y2_train.shape, Y2_test.shape)\n",
        "\n",
        "#Splitting into train and validation \n",
        "split1 = int(0.8 * X1_train.shape[0])\n",
        "split2 = int(0.8 * X2_train.shape[0])\n",
        "\n",
        "x1_val = X1_train[split1:]\n",
        "x1_train = X1_train[:split1]\n",
        "y1_val = Y1_train[split1:]\n",
        "y1_train = Y1_train[:split1]\n",
        "\n",
        "x2_val = X2_train[split2:]\n",
        "x2_train = X2_train[:split2]\n",
        "y2_val = Y2_train[split2:]\n",
        "y2_train = Y2_train[:split2]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 32, 32, 3) (5000, 32, 32, 3)\n",
            "(25000, 5) (5000, 5)\n",
            "(25000, 32, 32, 3) (5000, 32, 32, 3)\n",
            "(25000, 10) (5000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_GEFxHNhgu31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "13466d7c-6240-4ff7-f93c-235e94b169c5"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "#model architecture\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Measuring the run time of the model\n",
        "import time, datetime\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "hist1 = model.fit(x1_train, y1_train, epochs=10, batch_size=100, validation_data=(x1_val, y1_val), verbose=2)\n",
        "\n",
        "time_taken = datetime.datetime.now() - start\n",
        "print ('\\n'*2, '-'*20, '\\n')\n",
        "print ('Time taken for first training: ', time_taken)\n",
        "print ('\\n', '-'*20, '\\n'*2)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 28, 28, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 12, 12, 8)         1160      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 154,909\n",
            "Trainable params: 154,909\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            " - 47s - loss: 1.1968 - acc: 0.4910 - val_loss: 0.9886 - val_acc: 0.5910\n",
            "Epoch 2/10\n",
            " - 45s - loss: 1.0007 - acc: 0.5855 - val_loss: 0.9281 - val_acc: 0.6268\n",
            "Epoch 3/10\n",
            " - 45s - loss: 0.9280 - acc: 0.6244 - val_loss: 0.8914 - val_acc: 0.6414\n",
            "Epoch 4/10\n",
            " - 45s - loss: 0.8854 - acc: 0.6437 - val_loss: 0.8326 - val_acc: 0.6816\n",
            "Epoch 5/10\n",
            " - 45s - loss: 0.8455 - acc: 0.6669 - val_loss: 0.8039 - val_acc: 0.6938\n",
            "Epoch 6/10\n",
            " - 45s - loss: 0.8108 - acc: 0.6775 - val_loss: 0.8186 - val_acc: 0.6788\n",
            "Epoch 7/10\n",
            " - 45s - loss: 0.7950 - acc: 0.6848 - val_loss: 0.7640 - val_acc: 0.7050\n",
            "Epoch 8/10\n",
            " - 45s - loss: 0.7669 - acc: 0.6999 - val_loss: 0.7531 - val_acc: 0.7118\n",
            "Epoch 9/10\n",
            " - 45s - loss: 0.7372 - acc: 0.7108 - val_loss: 0.7461 - val_acc: 0.7128\n",
            "Epoch 10/10\n",
            " - 45s - loss: 0.7126 - acc: 0.7252 - val_loss: 0.7360 - val_acc: 0.7176\n",
            "\n",
            "\n",
            " -------------------- \n",
            "\n",
            "Time taken for first training:  0:07:34.310490\n",
            "\n",
            " -------------------- \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9MI8gz-xxszB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a550843-0aa3-42a1-94f2-a25fa51960f9"
      },
      "cell_type": "code",
      "source": [
        "# Final evaluation of the model\n",
        "    scores = model.evaluate(X1_test, Y1_test, verbose=0)\n",
        "    print(\"Accuracy: \"+ str(scores[1]*100)+\"%\")\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 71.67999999999999%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FUTUQ7ujiFtN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "51cea341-639d-4896-f90e-d1b4d9fe7018"
      },
      "cell_type": "code",
      "source": [
        "#Freezing the first 6 layers\n",
        "for l in model.layers[:6]:\n",
        "    l.trainable = False   \n",
        "\n",
        "\n",
        "\n",
        "trans_model = Sequential(model.layers[:6])\n",
        "\n",
        "trans_model.add(Dense(128, activation='relu'))\n",
        "trans_model.add(Dropout(0.4))\n",
        "trans_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "trans_model.summary()\n",
        "trans_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "hist2 = trans_model.fit(x2_train, y2_train, epochs=10, batch_size=100, validation_data=(x2_val, y2_val), verbose=2)\n",
        "time_taken = datetime.datetime.now() - start\n",
        "print ('\\n'*2, '-'*20, '\\n')\n",
        "print ('Time taken for final training: ', time_taken)\n",
        "print ('\\n', '-'*20, '\\n'*2)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 28, 28, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 12, 12, 8)         1160      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 155,554\n",
            "Trainable params: 148,874\n",
            "Non-trainable params: 6,680\n",
            "_________________________________________________________________\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            " - 18s - loss: 0.9331 - acc: 0.6443 - val_loss: 0.6940 - val_acc: 0.7414\n",
            "Epoch 2/10\n",
            " - 16s - loss: 0.7392 - acc: 0.7214 - val_loss: 0.6568 - val_acc: 0.7546\n",
            "Epoch 3/10\n",
            " - 16s - loss: 0.7106 - acc: 0.7290 - val_loss: 0.6392 - val_acc: 0.7638\n",
            "Epoch 4/10\n",
            " - 16s - loss: 0.6839 - acc: 0.7432 - val_loss: 0.6317 - val_acc: 0.7618\n",
            "Epoch 5/10\n",
            " - 16s - loss: 0.6625 - acc: 0.7509 - val_loss: 0.6158 - val_acc: 0.7664\n",
            "Epoch 6/10\n",
            " - 16s - loss: 0.6497 - acc: 0.7535 - val_loss: 0.6074 - val_acc: 0.7746\n",
            "Epoch 7/10\n",
            " - 16s - loss: 0.6346 - acc: 0.7645 - val_loss: 0.5954 - val_acc: 0.7748\n",
            "Epoch 8/10\n",
            " - 16s - loss: 0.6205 - acc: 0.7679 - val_loss: 0.5810 - val_acc: 0.7830\n",
            "Epoch 9/10\n",
            " - 16s - loss: 0.6022 - acc: 0.7759 - val_loss: 0.5732 - val_acc: 0.7878\n",
            "Epoch 10/10\n",
            " - 16s - loss: 0.5973 - acc: 0.7794 - val_loss: 0.5689 - val_acc: 0.7898\n",
            "\n",
            "\n",
            " -------------------- \n",
            "\n",
            "Time taken for final training:  0:02:46.262425\n",
            "\n",
            " -------------------- \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q6Kkqwj0szKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9e7d22f-ccc0-4911-c23b-76a5396c9572"
      },
      "cell_type": "code",
      "source": [
        "# Final evaluation of the model\n",
        "    scores = trans_model.evaluate(X2_test, Y2_test, verbose=0)\n",
        "    print(\"Accuracy: \"+ str(scores[1]*100)+\"%\")\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 78.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AGuW6DpwyHEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "ae12244a-398e-4afd-bb92-9cd07bfc3ade"
      },
      "cell_type": "code",
      "source": [
        "#Transfer learning and data augmentation\n",
        "#Freezing the first 6 layers\n",
        "for l in model.layers[:6]:\n",
        "    l.trainable = False   \n",
        "\n",
        "\n",
        "\n",
        "trans_model_1 = Sequential(model.layers[:6])\n",
        "\n",
        "trans_model_1.add(Dense(128, activation='relu'))\n",
        "trans_model_1.add(Dropout(0.4))\n",
        "trans_model_1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "trans_model_1.summary()\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "trans_model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.1, # randomly zoom into images\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "hist3 = trans_model_1.fit_generator(datagen.flow(x2_train, y2_train, batch_size=100), epochs=10,validation_data=(x2_val, y2_val), verbose=2)\n",
        "time_taken = datetime.datetime.now() - start\n",
        "print ('\\n'*2, '-'*20, '\\n')\n",
        "print ('Time taken for final training: ', time_taken)\n",
        "print ('\\n', '-'*20, '\\n'*2)\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 28, 28, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 12, 12, 8)         1160      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 155,554\n",
            "Trainable params: 148,874\n",
            "Non-trainable params: 6,680\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            " - 25s - loss: 1.0181 - acc: 0.6057 - val_loss: 0.7537 - val_acc: 0.7180\n",
            "Epoch 2/10\n",
            " - 23s - loss: 0.8506 - acc: 0.6737 - val_loss: 0.7375 - val_acc: 0.7168\n",
            "Epoch 3/10\n",
            " - 23s - loss: 0.8215 - acc: 0.6847 - val_loss: 0.6913 - val_acc: 0.7372\n",
            "Epoch 4/10\n",
            " - 23s - loss: 0.8026 - acc: 0.6915 - val_loss: 0.7042 - val_acc: 0.7306\n",
            "Epoch 5/10\n",
            " - 23s - loss: 0.7901 - acc: 0.6953 - val_loss: 0.6793 - val_acc: 0.7486\n",
            "Epoch 6/10\n",
            " - 23s - loss: 0.7813 - acc: 0.7026 - val_loss: 0.6603 - val_acc: 0.7456\n",
            "Epoch 7/10\n",
            " - 23s - loss: 0.7718 - acc: 0.7073 - val_loss: 0.6484 - val_acc: 0.7536\n",
            "Epoch 8/10\n",
            " - 23s - loss: 0.7647 - acc: 0.7080 - val_loss: 0.6455 - val_acc: 0.7534\n",
            "Epoch 9/10\n",
            " - 23s - loss: 0.7524 - acc: 0.7141 - val_loss: 0.6329 - val_acc: 0.7628\n",
            "Epoch 10/10\n",
            " - 23s - loss: 0.7486 - acc: 0.7163 - val_loss: 0.6314 - val_acc: 0.7628\n",
            "\n",
            "\n",
            " -------------------- \n",
            "\n",
            "Time taken for final training:  0:03:54.133445\n",
            "\n",
            " -------------------- \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L0b9TR77nzJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7584039d-234b-4c0d-9b33-a81907e9e3b7"
      },
      "cell_type": "code",
      "source": [
        "# Final evaluation of the model\n",
        "    scores = trans_model_1.evaluate(X2_test, Y2_test, verbose=0)\n",
        "    print(\"Accuracy: \"+ str(scores[1]*100)+\"%\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 76.22%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fGIh3MBSn107",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "16cce240-a5b1-4d57-bb72-4b4bc738c1c7"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 66,
      "outputs": []
    }
  ]
}