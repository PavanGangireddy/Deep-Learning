{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_cifar_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/malinenimaurya/Deep-Learning/blob/master/transfer_learning_cifar_keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DV6D2v1WiA8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        },
        "outputId": "70c58cf6-defe-44ac-e4f7-0cc412dd8568"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Dense, Convolution2D, Flatten, Activation, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "n_examples = 50000\n",
        "\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "X1_train = []\n",
        "X1_test = []\n",
        "X2_train = []\n",
        "X2_test = []\n",
        "Y1_train = []\n",
        "Y1_test = []\n",
        "Y2_train = []\n",
        "Y2_test = []\n",
        "\n",
        "for ix in range(n_examples):\n",
        "    if y_train[ix] < 5:\n",
        "        # put data in set 1\n",
        "        X1_train.append(x_train[ix]/255.0)\n",
        "        Y1_train.append(y_train[ix])\n",
        "    else:\n",
        "        # put data in set 2\n",
        "        X2_train.append(x_train[ix]/255.0)\n",
        "        Y2_train.append(y_train[ix])\n",
        "\n",
        "for ix in range(y_test.shape[0]):\n",
        "    if y_test[ix] < 5:\n",
        "        # put data in set 1\n",
        "        X1_test.append(x_test[ix]/255.0)\n",
        "        Y1_test.append(y_test[ix])\n",
        "    else:\n",
        "        # put data in set 2\n",
        "        X2_test.append(x_test[ix]/255.0)\n",
        "        Y2_test.append(y_test[ix])\n",
        "\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "X1_train = np.asarray(X1_train).reshape((-1, 32, 32, 3))\n",
        "X1_test = np.asarray(X1_test).reshape((-1, 32, 32, 3))\n",
        "X2_train = np.asarray(X2_train).reshape((-1, 32, 32, 3))\n",
        "X2_test = np.asarray(X2_test).reshape((-1, 32, 32, 3))\n",
        "\n",
        "Y1_train = to_categorical(np.asarray(Y1_train))\n",
        "Y1_test = to_categorical(np.asarray(Y1_test))\n",
        "\n",
        "Y2_train = to_categorical(np.asarray(Y2_train))\n",
        "Y2_test = to_categorical(np.asarray(Y2_test))\n",
        "\n",
        "\n",
        "# In[18]:\n",
        "\n",
        "print (X1_train.shape, X1_test.shape)\n",
        "print (Y1_train.shape, Y1_test.shape)\n",
        "\n",
        "\n",
        "# In[26]:\n",
        "\n",
        "split1 = int(0.8 * X1_train.shape[0])\n",
        "split2 = int(0.8 * X2_train.shape[0])\n",
        "\n",
        "x1_val = X1_train[split1:]\n",
        "x1_train = X1_train[:split1]\n",
        "y1_val = Y1_train[split1:]\n",
        "y1_train = Y1_train[:split1]\n",
        "\n",
        "x2_val = X2_train[split2:]\n",
        "x2_train = X2_train[:split2]\n",
        "y2_val = Y2_train[split2:]\n",
        "y2_train = Y2_train[:split2]\n",
        "\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, 5, 5, input_shape=(32, 32, 3), activation='relu'))\n",
        "model.add(Convolution2D(16, 5, 5, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.42))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "import time, datetime\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "hist1 = model.fit(x1_train, y1_train,\n",
        "         nb_epoch=10,\n",
        "         shuffle=True,\n",
        "         batch_size=100,\n",
        "         validation_data=(x1_val, y1_val), verbose=2)\n",
        "\n",
        "time_taken = datetime.datetime.now() - start\n",
        "print ('\\n'*2, '-'*20, '\\n')\n",
        "print ('Time taken for first training: ', time_taken)\n",
        "print ('\\n', '-'*20, '\\n'*2)\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 32, 32, 3) (5000, 32, 32, 3)\n",
            "(25000, 5) (5000, 5)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        2432      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        12816     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 8)         1160      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 119,581\n",
            "Trainable params: 119,581\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            " - 77s - loss: 1.1830 - acc: 0.4986 - val_loss: 1.0479 - val_acc: 0.5692\n",
            "Epoch 2/10\n",
            " - 77s - loss: 0.9972 - acc: 0.5911 - val_loss: 0.9394 - val_acc: 0.6200\n",
            "Epoch 3/10\n",
            " - 77s - loss: 0.9307 - acc: 0.6243 - val_loss: 0.8809 - val_acc: 0.6606\n",
            "Epoch 4/10\n",
            " - 76s - loss: 0.8975 - acc: 0.6411 - val_loss: 0.8556 - val_acc: 0.6600\n",
            "Epoch 5/10\n",
            " - 77s - loss: 0.8695 - acc: 0.6518 - val_loss: 0.8711 - val_acc: 0.6580\n",
            "Epoch 6/10\n",
            " - 77s - loss: 0.8371 - acc: 0.6652 - val_loss: 0.8518 - val_acc: 0.6618\n",
            "Epoch 7/10\n",
            " - 77s - loss: 0.8286 - acc: 0.6698 - val_loss: 0.8286 - val_acc: 0.6704\n",
            "Epoch 8/10\n",
            " - 76s - loss: 0.7989 - acc: 0.6887 - val_loss: 0.8113 - val_acc: 0.6862\n",
            "Epoch 9/10\n",
            " - 77s - loss: 0.7764 - acc: 0.6954 - val_loss: 0.7800 - val_acc: 0.6972\n",
            "Epoch 10/10\n",
            " - 77s - loss: 0.7506 - acc: 0.7056 - val_loss: 0.7580 - val_acc: 0.7010\n",
            "\n",
            "\n",
            " -------------------- \n",
            "\n",
            "Time taken for first training:  0:12:45.928228\n",
            "\n",
            " -------------------- \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FUTUQ7ujiFtN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "52168930-b5e6-4974-cb1e-1035fa10d13d"
      },
      "cell_type": "code",
      "source": [
        "# In[31]:\n",
        "\n",
        "for l in model.layers[:6]:\n",
        "    l.trainable = False   \n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "trans_model = Sequential(model.layers[:6])\n",
        "\n",
        "trans_model.add(Dense(128))\n",
        "trans_model.add(Activation('relu'))\n",
        "trans_model.add(Dense(10))\n",
        "trans_model.add(Activation('softmax'))\n",
        "\n",
        "trans_model.summary()\n",
        "trans_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "hist2 = trans_model.fit(x2_train, y2_train, nb_epoch=10, shuffle=True, batch_size=100, validation_data=(x2_val, y2_val), verbose=2)\n",
        "time_taken = datetime.datetime.now() - start\n",
        "print ('\\n'*2, '-'*20, '\\n')\n",
        "print ('Time taken for final training: ', time_taken)\n",
        "print ('\\n', '-'*20, '\\n'*2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        2432      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        12816     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 8)         1160      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 120,226\n",
            "Trainable params: 103,818\n",
            "Non-trainable params: 16,408\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            " - 30s - loss: 0.9334 - acc: 0.6449 - val_loss: 0.7724 - val_acc: 0.7056\n",
            "Epoch 2/10\n",
            " - 31s - loss: 0.8090 - acc: 0.6901 - val_loss: 0.7480 - val_acc: 0.7186\n",
            "Epoch 3/10\n",
            " - 31s - loss: 0.7782 - acc: 0.7046 - val_loss: 0.7398 - val_acc: 0.7166\n",
            "Epoch 4/10\n",
            " - 31s - loss: 0.7579 - acc: 0.7127 - val_loss: 0.7195 - val_acc: 0.7254\n",
            "Epoch 5/10\n",
            " - 31s - loss: 0.7320 - acc: 0.7205 - val_loss: 0.6799 - val_acc: 0.7424\n",
            "Epoch 6/10\n",
            " - 31s - loss: 0.7123 - acc: 0.7260 - val_loss: 0.6743 - val_acc: 0.7424\n",
            "Epoch 7/10\n",
            " - 31s - loss: 0.6976 - acc: 0.7387 - val_loss: 0.6595 - val_acc: 0.7566\n",
            "Epoch 8/10\n",
            " - 31s - loss: 0.6782 - acc: 0.7416 - val_loss: 0.6513 - val_acc: 0.7536\n",
            "Epoch 9/10\n",
            " - 31s - loss: 0.6667 - acc: 0.7496 - val_loss: 0.6456 - val_acc: 0.7560\n",
            "Epoch 10/10\n",
            " - 31s - loss: 0.6541 - acc: 0.7535 - val_loss: 0.6485 - val_acc: 0.7576\n",
            "\n",
            "\n",
            " -------------------- \n",
            "\n",
            "Time taken for final training:  0:05:08.480310\n",
            "\n",
            " -------------------- \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q6Kkqwj0szKY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}