{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_cifar_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/malinenimaurya/Deep-Learning/blob/master/transfer_learning_cifar_keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DV6D2v1WiA8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bb6b4572-83bc-48a9-caa3-41a4525074dc"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "np.random.seed(10)\n",
        "\n",
        "#Loading data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v2DEEtG5sesB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abc816d1-a2e2-41f4-e7ee-b04c1c589d11"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape[0]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "ssg75TZRfEx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "28d85a25-0edd-4767-cf45-7e019378df68"
      },
      "cell_type": "code",
      "source": [
        "#Normalising the data and dividing the dataset into two halves for training one model from scratch and on other halve to perform transfer learning\n",
        "\n",
        "X1_train = []\n",
        "X1_test = []\n",
        "X2_train = []\n",
        "X2_test = []\n",
        "Y1_train = []\n",
        "Y1_test = []\n",
        "Y2_train = []\n",
        "Y2_test = []\n",
        "\n",
        "for i in range(x_train.shape[0]):\n",
        "    if y_train[i] < 5:\n",
        "        # put data in set 1\n",
        "        X1_train.append(x_train[i]/255.0)\n",
        "        Y1_train.append(y_train[i])\n",
        "    else:\n",
        "        # put data in set 2\n",
        "        X2_train.append(x_train[i]/255.0)\n",
        "        Y2_train.append(y_train[i])\n",
        "\n",
        "for i in range(x_test.shape[0]):\n",
        "    if y_test[i] < 5:\n",
        "        # put data in set 1\n",
        "        X1_test.append(x_test[i]/255.0)\n",
        "        Y1_test.append(y_test[i])\n",
        "    else:\n",
        "        # put data in set 2\n",
        "        X2_test.append(x_test[i]/255.0)\n",
        "        Y2_test.append(y_test[i])\n",
        "\n",
        "#Converting to numpy array\n",
        "\n",
        "X1_train = np.asarray(X1_train).reshape((-1, 32, 32, 3))\n",
        "X1_test = np.asarray(X1_test).reshape((-1, 32, 32, 3))\n",
        "X2_train = np.asarray(X2_train).reshape((-1, 32, 32, 3))\n",
        "X2_test = np.asarray(X2_test).reshape((-1, 32, 32, 3))\n",
        "\n",
        "#one hot encoding\n",
        "Y1_train = to_categorical(Y1_train)\n",
        "Y1_test = to_categorical(Y1_test)\n",
        "\n",
        "Y2_train = to_categorical(Y2_train)\n",
        "Y2_test = to_categorical(Y2_test)\n",
        "\n",
        "print (X1_train.shape, X1_test.shape)\n",
        "print (Y1_train.shape, Y1_test.shape)\n",
        "print (X2_train.shape, X2_test.shape)\n",
        "print (Y2_train.shape, Y2_test.shape)\n",
        "\n",
        "#Splitting into train and validation \n",
        "split1 = int(0.8 * X1_train.shape[0])\n",
        "split2 = int(0.8 * X2_train.shape[0])\n",
        "\n",
        "x1_val = X1_train[split1:]\n",
        "x1_train = X1_train[:split1]\n",
        "y1_val = Y1_train[split1:]\n",
        "y1_train = Y1_train[:split1]\n",
        "\n",
        "x2_val = X2_train[split2:]\n",
        "x2_train = X2_train[:split2]\n",
        "y2_val = Y2_train[split2:]\n",
        "y2_train = Y2_train[:split2]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 32, 32, 3) (5000, 32, 32, 3)\n",
            "(25000, 5) (5000, 5)\n",
            "(25000, 32, 32, 3) (5000, 32, 32, 3)\n",
            "(25000, 10) (5000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_GEFxHNhgu31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "4e1289da-59d5-4332-fb2b-be5f00c458a2"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "#model architecture\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Measuring the run time of the model\n",
        "import time, datetime\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "hist1 = model.fit(x1_train, y1_train,\n",
        "         epochs=10,\n",
        "         shuffle=True,\n",
        "         batch_size=100,\n",
        "         validation_data=(x1_val, y1_val), verbose=2)\n",
        "\n",
        "time_taken = datetime.datetime.now() - start\n",
        "print ('\\n'*2, '-'*20, '\\n')\n",
        "print ('Time taken for first training: ', time_taken)\n",
        "print ('\\n', '-'*20, '\\n'*2)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 12, 12, 8)         1160      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 154,909\n",
            "Trainable params: 154,909\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            " - 45s - loss: 1.1976 - acc: 0.4895 - val_loss: 0.9959 - val_acc: 0.5814\n",
            "Epoch 2/10\n",
            " - 44s - loss: 1.0020 - acc: 0.5867 - val_loss: 0.9206 - val_acc: 0.6292\n",
            "Epoch 3/10\n",
            " - 44s - loss: 0.9253 - acc: 0.6265 - val_loss: 0.8637 - val_acc: 0.6558\n",
            "Epoch 4/10\n",
            " - 44s - loss: 0.8766 - acc: 0.6478 - val_loss: 0.8274 - val_acc: 0.6806\n",
            "Epoch 5/10\n",
            " - 44s - loss: 0.8345 - acc: 0.6692 - val_loss: 0.7939 - val_acc: 0.6952\n",
            "Epoch 6/10\n",
            " - 44s - loss: 0.8001 - acc: 0.6828 - val_loss: 0.8032 - val_acc: 0.6874\n",
            "Epoch 7/10\n",
            " - 44s - loss: 0.7852 - acc: 0.6903 - val_loss: 0.7489 - val_acc: 0.7152\n",
            "Epoch 8/10\n",
            " - 45s - loss: 0.7548 - acc: 0.7060 - val_loss: 0.7484 - val_acc: 0.7160\n",
            "Epoch 9/10\n",
            " - 45s - loss: 0.7304 - acc: 0.7150 - val_loss: 0.7295 - val_acc: 0.7258\n",
            "Epoch 10/10\n",
            " - 45s - loss: 0.7034 - acc: 0.7275 - val_loss: 0.7227 - val_acc: 0.7296\n",
            "\n",
            "\n",
            " -------------------- \n",
            "\n",
            "Time taken for first training:  0:07:25.022844\n",
            "\n",
            " -------------------- \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9MI8gz-xxszB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08afc59e-6be6-42fd-af95-8e9d0a71f4dd"
      },
      "cell_type": "code",
      "source": [
        "# Final evaluation of the model\n",
        "    scores = model.evaluate(X1_test, Y1_test, verbose=0)\n",
        "    print(\"Accuracy: \"+ str(scores[1]*100)+\"%\")\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 72.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FUTUQ7ujiFtN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "cf2d7053-fe09-45e3-f5c6-0f8b51fcfcbf"
      },
      "cell_type": "code",
      "source": [
        "#Freezing the first 6 layers\n",
        "for l in model.layers[:6]:\n",
        "    l.trainable = False   \n",
        "\n",
        "\n",
        "\n",
        "trans_model = Sequential(model.layers[:6])\n",
        "\n",
        "trans_model.add(Dense(128, activation='relu'))\n",
        "trans_model.add(Dropout(0.4))\n",
        "trans_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "trans_model.summary()\n",
        "trans_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "hist2 = trans_model.fit(x2_train, y2_train, epochs=10, shuffle=True, batch_size=100, validation_data=(x2_val, y2_val), verbose=2)\n",
        "time_taken = datetime.datetime.now() - start\n",
        "print ('\\n'*2, '-'*20, '\\n')\n",
        "print ('Time taken for final training: ', time_taken)\n",
        "print ('\\n', '-'*20, '\\n'*2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 12, 12, 8)         1160      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 155,554\n",
            "Trainable params: 148,874\n",
            "Non-trainable params: 6,680\n",
            "_________________________________________________________________\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            " - 17s - loss: 0.9280 - acc: 0.6451 - val_loss: 0.7016 - val_acc: 0.7350\n",
            "Epoch 2/10\n",
            " - 16s - loss: 0.7407 - acc: 0.7221 - val_loss: 0.6664 - val_acc: 0.7476\n",
            "Epoch 3/10\n",
            " - 16s - loss: 0.7136 - acc: 0.7295 - val_loss: 0.6506 - val_acc: 0.7540\n",
            "Epoch 4/10\n",
            " - 16s - loss: 0.6870 - acc: 0.7423 - val_loss: 0.6408 - val_acc: 0.7556\n",
            "Epoch 5/10\n",
            " - 16s - loss: 0.6656 - acc: 0.7488 - val_loss: 0.6245 - val_acc: 0.7692\n",
            "Epoch 6/10\n",
            " - 16s - loss: 0.6520 - acc: 0.7541 - val_loss: 0.6183 - val_acc: 0.7698\n",
            "Epoch 7/10\n",
            " - 16s - loss: 0.6314 - acc: 0.7613 - val_loss: 0.6045 - val_acc: 0.7652\n",
            "Epoch 8/10\n",
            " - 16s - loss: 0.6195 - acc: 0.7680 - val_loss: 0.5912 - val_acc: 0.7772\n",
            "Epoch 9/10\n",
            " - 16s - loss: 0.5992 - acc: 0.7796 - val_loss: 0.5817 - val_acc: 0.7792\n",
            "Epoch 10/10\n",
            " - 16s - loss: 0.5945 - acc: 0.7788 - val_loss: 0.5764 - val_acc: 0.7844\n",
            "\n",
            "\n",
            " -------------------- \n",
            "\n",
            "Time taken for final training:  0:02:45.459116\n",
            "\n",
            " -------------------- \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q6Kkqwj0szKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "044aa14c-d1ba-490a-bff7-bb45b4700b32"
      },
      "cell_type": "code",
      "source": [
        "# Final evaluation of the model\n",
        "    scores = trans_model.evaluate(X2_test, Y2_test, verbose=0)\n",
        "    print(\"Accuracy: \"+ str(scores[1]*100)+\"%\")\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 79.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AGuW6DpwyHEz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}